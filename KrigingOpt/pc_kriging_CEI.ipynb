{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import chaospy as cp\n",
    "import GPy\n",
    "\n",
    "class SequentialPCKriging:\n",
    "    def __init__(self, input_dist, order=3):\n",
    "        self.input_dist = input_dist\n",
    "        self.expansion = cp.generate_expansion(order, input_dist)\n",
    "        self.gp_model = None\n",
    "\n",
    "    def fit_pce(self, x, y):\n",
    "        self.pce_model = cp.fit_regression(self.expansion, x.T, y)\n",
    "\n",
    "    def pce_predict(self, x):\n",
    "        return self.pce_model(x)\n",
    "\n",
    "    def fit_kriging(self, x, y):\n",
    "        discrepancy = y - self.pce_predict(x)\n",
    "        print(y.shape)\n",
    "        print(self.pce_predict(x))\n",
    "        print(discrepancy.shape)\n",
    "        kernel = GPy.kern.RBF(input_dim=2, variance=1., lengthscale=1.)\n",
    "        self.gp_model = GPy.models.GPRegression(x, discrepancy, kernel)\n",
    "        self.gp_model.optimize()\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        self.fit_pce(x, y)\n",
    "        self.fit_kriging(x, y)\n",
    "\n",
    "    def predict(self, x_new):\n",
    "        pce_pred = self.pce_predict(x_new)\n",
    "        gp_pred, gp_var = self.gp_model.predict(x_new)\n",
    "        return pce_pred + gp_pred, np.sqrt(gp_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Expected Improvement\n",
    "\n",
    "The idea of this acquisition function here is that\n",
    "\n",
    "First, we find the current best in our samples $Y^{s}$: $ \\hat{y}_n = \\textbf{max}_{1 \\le i \\le n} Y^{s}_i $\n",
    "\n",
    "Then over the space of hypothetical simulation:\n",
    "\n",
    "$$ a(x,y) = \\textbf{max} \\{ 0, y - \\hat_{y}_n \\} $$\n",
    "\n",
    "The improvement function:\n",
    "\n",
    "$$ a(x,y) = \\int_{-\\infty}^{\\infty} \\textbf{max} \\{ 0, y - \\hat_{y}_n \\} p(y|x) dy $$\n",
    "\n",
    "The closed-form expression:\n",
    "\n",
    "$$ a(x) = (m(x)-\\hat{y}_{n}) \\Phi(Z) + \\sigma (x) \\phi  (Z) $$\n",
    "$$ Z = \\frac{m(x)-\\hat{y}_n}{\\sigma (x)} $$\n",
    "\n",
    "Note here it does not really matter what the metamodel is, the only assumption made here is that our predictive distribution is Gaussian.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "def constrained_expected_improvement(X, X_sample, Y_sample, f_sur, g_sur, xi=0.01):\n",
    "    '''\n",
    "    Computes the Constrained Expected Improvement (CEI) at points X based on existing\n",
    "    samples X_sample and Y_sample using a Gaussian process surrogate model for the\n",
    "    objective function and a constraint.\n",
    "\n",
    "    Args:\n",
    "    X: Points at which CEI shall be computed (m x d).\n",
    "    X_sample: Sample locations (n x d).\n",
    "    Y_sample: Sample values (n x 1).\n",
    "    f_sur: A trained surrogate model for the objective function.\n",
    "    g_sur: A trained surrogate model for the constraint.\n",
    "    xi: Exploitation-exploration trade-off parameter.\n",
    "\n",
    "    Returns:\n",
    "    Constrained Expected Improvements at points X.\n",
    "    '''\n",
    "    # Making a prediction at point X for the objective function\n",
    "    mu_f, sigma_f = f_sur.predict(X, return_std=True)\n",
    "\n",
    "    # Calculating the improvement for the objective function\n",
    "    mu_sample_opt = np.max(Y_sample)\n",
    "    imp_f = mu_f - mu_sample_opt - xi\n",
    "    Z_f = imp_f / sigma_f\n",
    "    ei = imp_f * norm.cdf(Z_f) + sigma_f * norm.pdf(Z_f)\n",
    "    ei[sigma_f == 0.0] = 0.0  # If sigma_f is 0, the expected improvement is 0\n",
    "\n",
    "    # Making a prediction at point X for the constraint\n",
    "    mu_g, sigma_g = g_sur.predict(X, return_std=True)\n",
    "\n",
    "    # Calculating the probability of feasibility\n",
    "    P_feasibility = norm.cdf(0, loc=mu_g, scale=sigma_g)\n",
    "\n",
    "    # Multiplying EI by the probability of feasibility\n",
    "    cei = ei * P_feasibility\n",
    "\n",
    "    return cei\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "def propose_location_constrained(acquisition, X_sample, Y_sample, fk, gk, bounds, xi=0.01):\n",
    "    \"\"\"\n",
    "    Proposes the next sampling point by optimizing the constrained acquisition function.\n",
    "\n",
    "    Args:\n",
    "        acquisition: Acquisition function.\n",
    "        X_sample: Sample locations (n x d).\n",
    "        Y_sample: Sample values (n x 1).\n",
    "        fk: Trained surrogate model for objective function.\n",
    "        gk: Trained surrogate model for constraint.\n",
    "        bounds: Bounds of the design space (2d array).\n",
    "        xi: Exploration-exploitation trade-off parameter.\n",
    "\n",
    "    Returns:\n",
    "        Location of the next sampling point.\n",
    "    \"\"\"\n",
    "    dim = X_sample.shape[1]\n",
    "    min_val = 1\n",
    "    min_x = None\n",
    "\n",
    "    def min_obj(X):\n",
    "        # Minimization objective is the negative acquisition function\n",
    "        return -acquisition(X.reshape(-1, dim), X_sample, Y_sample, fk, gk, xi)\n",
    "\n",
    "    # Start from multiple points to avoid local minima\n",
    "    for starting_point in np.random.uniform(bounds[:, 0], bounds[:, 1], size=(10, dim)):\n",
    "        res = minimize(min_obj, starting_point.reshape(1, -1), bounds=bounds, method='L-BFGS-B')\n",
    "        if res.fun < min_val:\n",
    "            min_val = res.fun[0]\n",
    "            min_x = res.x\n",
    "\n",
    "    return min_x.reshape(-1, 1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "outputs": [],
   "source": [
    "def optimize(f, g, bounds, input_dist, n_iter=25, initial_samples=5, xi=0.01):\n",
    "    \"\"\"\n",
    "    Main optimization loop with constraints.\n",
    "\n",
    "    Args:\n",
    "        f: Objective function.\n",
    "        g: Constraint function (should be <= 0 for feasible points).\n",
    "        bounds: Bounds of the design space (2d array).\n",
    "        n_iter: Number of iterations.\n",
    "        initial_samples: Number of initial random samples.\n",
    "        xi: Exploration-exploitation trade-off parameter.\n",
    "\n",
    "    Returns:\n",
    "        Optimal value and corresponding point.\n",
    "    \"\"\"\n",
    "    # Randomly sample the initial design space\n",
    "    X_sample = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(initial_samples, len(bounds)))\n",
    "    Y_sample = np.array([f(x) for x in X_sample])\n",
    "    Yg_sample = np.array([g(x) for x in X_sample])\n",
    "\n",
    "    # Initialize and fit Kriging models\n",
    "    fk = SequentialPCKriging(input_dist, order=5)\n",
    "    gk = SequentialPCKriging(input_dist, order=5)\n",
    "    fk.fit(X_sample, Y_sample)\n",
    "    gk.fit(X_sample, Yg_sample)\n",
    "\n",
    "    for i in range(n_iter):\n",
    "        fk.fit(X_sample, Y_sample)\n",
    "        gk.fit(X_sample, Yg_sample)\n",
    "\n",
    "        # Obtain the next sampling point and evaluate f and g\n",
    "        X_next = propose_location_constrained(constrained_expected_improvement, X_sample, Y_sample, fk, gk, bounds, xi)\n",
    "        Y_next = np.array([f(x) for x in X_next])\n",
    "        Yg_next = np.array([g(x) for x in X_next])\n",
    "\n",
    "        # Update samples\n",
    "        X_sample = np.vstack((X_sample, X_next))\n",
    "        Y_sample = np.append(Y_sample, Y_next)\n",
    "        Yg_sample = np.append(Yg_sample, Yg_next)\n",
    "\n",
    "    # Find the best feasible solution\n",
    "    feasible_mask = Yg_sample <= 0\n",
    "    if np.any(feasible_mask):\n",
    "        feasible_Y_sample = Y_sample[feasible_mask]\n",
    "        feasible_X_sample = X_sample[feasible_mask]\n",
    "        opt_val = np.max(feasible_Y_sample)\n",
    "        opt_point = feasible_X_sample[np.argmax(feasible_Y_sample)]\n",
    "    else:\n",
    "        opt_val = None\n",
    "        opt_point = None\n",
    "\n",
    "    return opt_val, opt_point\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (5,) (5,2) ",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[165], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# Test the optimization function\u001B[39;00m\n\u001B[0;32m     10\u001B[0m bounds \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray([[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m],\n\u001B[0;32m     11\u001B[0m                    [\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m1\u001B[39m]])  \u001B[38;5;66;03m# Bounds of the design space\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m opt_val, opt_point \u001B[38;5;241m=\u001B[39m \u001B[43moptimize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mg_test\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbounds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mUniform\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mn_iter\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitial_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxi\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.02\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimal Value:\u001B[39m\u001B[38;5;124m\"\u001B[39m, opt_val)\n\u001B[0;32m     15\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mOptimal Point:\u001B[39m\u001B[38;5;124m\"\u001B[39m, opt_point)\n",
      "Cell \u001B[1;32mIn[164], line 24\u001B[0m, in \u001B[0;36moptimize\u001B[1;34m(f, g, bounds, input_dist, n_iter, initial_samples, xi)\u001B[0m\n\u001B[0;32m     22\u001B[0m fk \u001B[38;5;241m=\u001B[39m SequentialPCKriging(input_dist, order\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[0;32m     23\u001B[0m gk \u001B[38;5;241m=\u001B[39m SequentialPCKriging(input_dist, order\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5\u001B[39m)\n\u001B[1;32m---> 24\u001B[0m \u001B[43mfk\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_sample\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mY_sample\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     25\u001B[0m gk\u001B[38;5;241m.\u001B[39mfit(X_sample, Yg_sample)\n\u001B[0;32m     27\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(n_iter):\n",
      "Cell \u001B[1;32mIn[161], line 28\u001B[0m, in \u001B[0;36mSequentialPCKriging.fit\u001B[1;34m(self, x, y)\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, y):\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfit_pce(x, y)\n\u001B[1;32m---> 28\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit_kriging\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[161], line 18\u001B[0m, in \u001B[0;36mSequentialPCKriging.fit_kriging\u001B[1;34m(self, x, y)\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mfit_kriging\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, y):\n\u001B[1;32m---> 18\u001B[0m     discrepancy \u001B[38;5;241m=\u001B[39m \u001B[43my\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpce_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m     \u001B[38;5;28mprint\u001B[39m(y\u001B[38;5;241m.\u001B[39mshape)\n\u001B[0;32m     20\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpce_predict(x))\n",
      "\u001B[1;31mValueError\u001B[0m: operands could not be broadcast together with shapes (5,) (5,2) "
     ]
    }
   ],
   "source": [
    "def f_test(x):\n",
    "    x1, x2 = x\n",
    "    return (4-2.1*x1**2 + 1/3*x1**4) * x1**2 + x1*x2 + (-4+4*x2**2)*x2**2\n",
    "\n",
    "def g_test(x):\n",
    "    x1, x2 = x\n",
    "    return -1\n",
    "\n",
    "# Test the optimization function\n",
    "bounds = np.array([[-1, 1],\n",
    "                   [-1, 1]])  # Bounds of the design space\n",
    "opt_val, opt_point = optimize(f_test, g_test, bounds, cp.Uniform(-1,1), n_iter=3, initial_samples=5, xi=0.02)\n",
    "\n",
    "print(\"Optimal Value:\", opt_val)\n",
    "print(\"Optimal Point:\", opt_point)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "X_sample = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(5, len(bounds)))\n",
    "Y_sample = np.array([f_test(x) for x in X_sample])\n",
    "expansion = cp.generate_expansion(5, cp.Uniform(-1,1))\n",
    "pce_model = cp.fit_regression(expansion, X_sample.T, Y_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.18021571,  1.12822619, -0.83127476, -0.74743496, -0.3725491 ],\n       [-1.50357188, -0.28331356,  5.20889964, 26.73076189, 24.3253513 ]])"
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pce_model(X_sample.T)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[ 0.18021571, -1.50357188],\n       [ 1.12822619, -0.28331356],\n       [-0.83127476,  5.20889964],\n       [-0.74743496, 26.73076189],\n       [-0.3725491 , 24.3253513 ]])"
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pce_model(X_sample)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}